---
description: Bug hunting and problem-solving approaches for persistent issues. Defines reconnaissance, problem framing, hypothesis generation, investigation, root-cause confirmation, fix strategy, execution, and verification. Apply when debugging or solving persistent problems.
alwaysApply: false
---

# Bug Hunting & Problem Solving

> **Note**: Assumes core rules (command execution, file operations, quality gates) are already loaded.

## 0 Â· Familiarisation & Mapping
- **Reconnaissance first.** Conduct a non-destructive survey of the repository, runtime substrate, configs, logs, and test suites to build an objective mental model of the current state.
- Produce a â‰¤ 200-line digest anchoring all subsequent analysis. **No mutations during this phase.**

## 1 Â· Problem Framing & Success Criteria
- Restate the observed behaviour, expected behaviour, and impact.
- Define concrete success criteria (e.g., failing test passes, latency < X ms).
- Invoke the clarification threshold only if epistemic conflict, missing resources, irreversible jeopardy, or research saturation arises.

## 2 Â· Context Gathering
- Enumerate artefactsâ€”source, configs, infra, tests, logs, dashboardsâ€”relevant to the failing pathway.
- Apply the token-aware filtering protocol (`head`, `wc -l`, `head -c`) to sample large outputs responsibly.
- Document scope: systems, services, data flows, security surfaces.

## 3 Â· Hypothesis Generation & Impact Assessment
- Brainstorm plausible root causes (config drift, regression, dependency mismatch, race condition, resource limits, etc.).
- Rank by likelihood Ã— blast radius.
- Note instrumentation or log gaps that may impede verification.

## 4 Â· Targeted Investigation & Diagnosis
- Probe highest-priority hypotheses first using safe, time-bounded commands.
- Capture fused stdout+stderr and exit codes for every diagnostic step.
- Eliminate or confirm hypotheses with concrete evidence.

## 5 Â· Root-Cause Confirmation & Fix Strategy
- Summarise the definitive root cause.
- Devise a minimal, reversible fix that addresses the underlying issueâ€”not a surface symptom.
- Consider test coverage: add/expand failing cases to prevent regressions.

## 6 Â· Execution & Autonomous Correction
- **Read before write; reread after write.**
- Use command execution patterns (see `core/command-execution.mdc`):
  - Self-terminating commands: `<command> 2>&1 | cat`
  - Non-terminating commands: `timeout <duration> <command> 2>&1 | cat`
- Use non-interactive flags when safe.
- **Never create unsolicited `.md` files**â€”all transient analysis stays in chat unless an artefact is explicitly requested.

## 7 Â· Verification & Regression Guard
- Re-run the failing test, full unit/integration suites, linters, and static analysis.
- Auto-rectify new failures until green or blocked by the clarification threshold.
- Capture and report key metrics (latency, error rates) to demonstrate resolution.

## 8 Â· Reporting & Live TODO
- Summarise: Root Cause, Fix Applied, Verification, Residual Risks / Recommendations
- Maintain an inline TODO ledger with âœ… / âš ï¸ / ğŸš§ markers if multi-phase follow-ups remain.
- All transient narratives remain in chat; no unsolicited Markdown reports.

## 9 Â· Continuous Improvement & Prospection
- Suggest durable enhancements (observability, resilience, performance, security) that would pre-empt similar failures.
- Provide impact estimates and outline next steps.
